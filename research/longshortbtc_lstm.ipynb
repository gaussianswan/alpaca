{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpaca.data.historical import CryptoHistoricalDataClient\n",
    "from alpaca.data.requests import CryptoBarsRequest\n",
    "from alpaca.data.timeframe import TimeFrame, TimeFrameUnit\n",
    "from alpaca.trading.client import TradingClient\n",
    "from alpaca.trading.requests import MarketOrderRequest\n",
    "from alpaca.trading.enums import OrderSide, TimeInForce\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import logging\n",
    "import asyncio\n",
    "import os\n",
    "import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "api_key = os.environ['ALPACA_PAPER_TRADING_KEY_ID']\n",
    "secret_key = os.environ['ALPACA_PAPER_TRADING_SECRET_KEY']\n",
    "trading_client = TradingClient(api_key = api_key, secret_key=secret_key)\n",
    "crypto_historical_data_client = CryptoHistoricalDataClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_historical_data_client = CryptoHistoricalDataClient()\n",
    "product = 'BTC/USD'\n",
    "start_time = datetime.datetime.utcnow() - datetime.timedelta(minutes = 15000)\n",
    "bars_request = CryptoBarsRequest(\n",
    "    symbol_or_symbols=product, \n",
    "    start = start_time, \n",
    "    timeframe=TimeFrame(amount = 15, unit = TimeFrameUnit.Minute)\n",
    ")\n",
    "\n",
    "df = crypto_historical_data_client.get_crypto_bars(bars_request).df\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_close'] = df['close'].apply(np.log)\n",
    "df['log_return'] = df['log_close'].diff()\n",
    "df.dropna(inplace = True)\n",
    "return_series = df['log_return'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our return series. Next, we are going to split our data into training set and test set. The dataset we have here is the past 100 period returns and then the target variable is the return in the next period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After we have this, we need to create an LSTM model with this\n",
    "num_neurons = 20\n",
    "dropout = 0.3\n",
    "\n",
    "model = Sequential() \n",
    "model.add(LSTM(\n",
    "    num_neurons, \n",
    "    input_shape = (100, 1), \n",
    "    return_sequences = True\n",
    "))\n",
    "\n",
    "model.add(Dropout(dropout))\n",
    "model.add(LSTM(num_neurons, return_sequences=True))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(LSTM(num_neurons))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Dense(units = 1))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(loss = 'mse', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() \n",
    "scaled_data = scaler.fit_transform(X = return_series.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 100\n",
    "x = [] \n",
    "y = []\n",
    "\n",
    "for i in range(look_back, return_series.shape[0]): \n",
    "    x_data = scaled_data[i- look_back:i]\n",
    "    y_data = scaled_data[i]\n",
    "\n",
    "    x.append(x_data)\n",
    "    y.append(y_data)\n",
    "\n",
    "x_train = np.array(x) \n",
    "y_train = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "29/29 [==============================] - 2s 53ms/step - loss: 0.0089\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 2s 62ms/step - loss: 0.0089\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 1s 49ms/step - loss: 0.0084\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 1s 48ms/step - loss: 0.0087\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 1s 50ms/step - loss: 0.0083\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 2s 52ms/step - loss: 0.0083\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 1s 50ms/step - loss: 0.0083\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 1s 51ms/step - loss: 0.0090\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 1s 51ms/step - loss: 0.0079\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 1s 51ms/step - loss: 0.0078\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 1s 47ms/step - loss: 0.0072\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 1s 50ms/step - loss: 0.0072\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 1s 50ms/step - loss: 0.0071\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 1s 51ms/step - loss: 0.0070\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 2s 53ms/step - loss: 0.0070\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 1s 50ms/step - loss: 0.0068\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 1s 51ms/step - loss: 0.0068\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 1s 49ms/step - loss: 0.0066\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 1s 49ms/step - loss: 0.0061\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 1s 50ms/step - loss: 0.0062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2266c297af0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 20, batch_size = 32, verbose = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the model fitted, we can take the data and make some predictions. We have to supply the same input format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = scaled_data[-look_back]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred_reshaped = np.reshape(x_pred, (1, x_pred.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(x_pred_reshaped).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array([float(prediction)])\n",
    "pred = np.reshape(pred, (pred.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_prediction = scaler.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02213778]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02189454]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we turn this into a simple return\n",
    "np.exp(true_prediction) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the neural net is predicting that in the next 15 minutes, there should be a negative 2.2% return on bitcoin. Maybe we would go short here and see what happens over the next 15 minutes. \n",
    "One thing that I don't fully understand is how the inputs work into the neural net. We trained it by giving it the 100 returns and having the next period return. Why are we giving it only one data point here, should we not be giving it the full 100 from the past. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('stonks')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "765fc2768b52b0fb7f29f4dd3ad83fea88a1669f139631a6056e52cdfd4fc226"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
